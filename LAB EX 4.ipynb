{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "e3XZd_dQEtmE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"xor_dataset.csv\")\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2rQmJd-GGSV",
        "outputId": "c0dad688-955a-473d-dcb5-aa7de278ce47"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   X1  X2  Y\n",
            "0   0   0  0\n",
            "1   0   1  1\n",
            "2   1   0  1\n",
            "3   1   1  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data[['X1', 'X2']].values\n",
        "y = data[['Y']].values"
      ],
      "metadata": {
        "id": "daJxLL-SGLGk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)"
      ],
      "metadata": {
        "id": "jm-ugIHGGM1F"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(1)\n",
        "\n",
        "input_layer = 2\n",
        "hidden_layer = 2\n",
        "output_layer = 1\n",
        "\n",
        "W1 = np.random.rand(input_layer, hidden_layer)\n",
        "b1 = np.random.rand(1, hidden_layer)\n",
        "\n",
        "W2 = np.random.rand(hidden_layer, output_layer)\n",
        "b2 = np.random.rand(1, output_layer)"
      ],
      "metadata": {
        "id": "eIPS1-x5GQTJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.5\n",
        "epochs = 10000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "\n",
        "    # FORWARD PROPAGATION\n",
        "    hidden_input = np.dot(X, W1) + b1\n",
        "    hidden_output = sigmoid(hidden_input)\n",
        "\n",
        "    final_input = np.dot(hidden_output, W2) + b2\n",
        "    predicted_output = sigmoid(final_input)\n",
        "\n",
        "    # ERROR CALCULATION\n",
        "    error = y - predicted_output\n",
        "\n",
        "    # BACKPROPAGATION\n",
        "    d_output = error * sigmoid_derivative(predicted_output)\n",
        "    d_hidden = d_output.dot(W2.T) * sigmoid_derivative(hidden_output)\n",
        "\n",
        "    # UPDATE WEIGHTS AND BIASES\n",
        "    W2 += hidden_output.T.dot(d_output) * learning_rate\n",
        "    b2 += np.sum(d_output, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    W1 += X.T.dot(d_hidden) * learning_rate\n",
        "    b1 += np.sum(d_hidden, axis=0, keepdims=True) * learning_rate"
      ],
      "metadata": {
        "id": "ja9xHTLeGU5a"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Final Output After Training:\")\n",
        "print(predicted_output.round())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFg5PuSaGWfs",
        "outputId": "8f0d61d6-a7da-4bb1-f35b-557e4bba22f4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Output After Training:\n",
            "[[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]]\n"
          ]
        }
      ]
    }
  ]
}